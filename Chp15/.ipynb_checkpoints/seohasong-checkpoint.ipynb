{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45825016  2.82441998 -1.12732375]\n",
      " [-0.91650033  5.64883995 -2.25464749]]\n",
      "[[ 1.13355064  1.95907474  3.20387125]\n",
      " [ 1.92831576  4.02181721  5.89067936]]\n",
      "[[ 1.106529    1.96943009  3.10343981]\n",
      " [ 1.94436979  4.01567841  5.94525337]]\n",
      "[[ 1.06652546  1.98155653  3.04392362]\n",
      " [ 1.96564746  4.00925779  5.97699547]]\n",
      "[[ 1.03292     1.99094868  3.01680088]\n",
      " [ 1.98309004  4.00449371  5.99126673]]\n",
      "[[  3.95334125   8.01264286  11.97905064]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "n_inputs = n_outputs = 3\n",
    "n_hidden = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    hidden = fully_connected(X, n_hidden, activation_fn=None)\n",
    "    outputs = fully_connected(hidden, n_outputs, activation_fn=None)\n",
    "\n",
    "    error = tf.square(outputs - X)\n",
    "    reconstruction_loss = tf.reduce_mean(error)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(reconstruction_loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        n_iterations = 1000    \n",
    "        X_train = [\n",
    "            [1, 2, 3],\n",
    "            [2, 4, 6]\n",
    "        ]\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for iteration in range(n_iterations):\n",
    "            xx, ouputs_val = sess.run([training_op, outputs], feed_dict={X: X_train})\n",
    "            if iteration%200==0:\n",
    "                print(ouputs_val)\n",
    "        output_val = outputs.eval(feed_dict={X: [[4, 8, 12]]})\n",
    "\n",
    "print(output_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation\n",
    "\n",
    "mnist에 오토인코딩을 적용해 봅시다. 평범한 다변수 딥러닝을 구축하는 것과 비슷합니다.\n",
    "\n",
    "minst는 [28 by 28] 형태의 데이타로 한개의 인스턴스는 784차원으로 이루어집니다.\n",
    "\n",
    "Codings까지 포함해 3개의 hidden 레이어를 사용해 봅시다. 아래 그림과 같은 구조입니다.\n",
    "\n",
    "![](1.png)\n",
    "\n",
    "###### (He 초기화, ELU 활성함수, l2 정규화) <= 이게 무슨뜻인가요?\n",
    "\n",
    "지금은 일단 학습하는 코드만 짜봅니다! 학습에 대한 테스트는 뒤에서 설명합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "5.247266054153442\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import time\n",
    "\n",
    "n_inputs = n_outputs = 28 * 28\n",
    "n_hidden1 = n_hidden3 = 300\n",
    "n_hidden2 = 150\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.001\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    with tf.contrib.framework.arg_scope(\n",
    "        [fully_connected],\n",
    "        activation_fn=tf.nn.elu,\n",
    "        weights_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "        weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    ):\n",
    "        hidden1 = fully_connected(X, n_hidden1)\n",
    "        hidden2 = fully_connected(hidden1, n_hidden2)\n",
    "        hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "        outputs = fully_connected(hidden3, n_outputs, activation_fn=None)\n",
    "        \n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        n_epochs = 1\n",
    "        batch_size = 100\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            n_batches = mnist.train.num_examples // batch_size\n",
    "            for iteration in range(n_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                xx, hidden2_val = sess.run([training_op, hidden2], feed_dict={X: X_batch})\n",
    "                \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying Weights\n",
    "\n",
    "위에서 만든 오토인코더처럼 디코더와 인코더가 대칭의 구조를 가지면, 디코더와 인코더 레이어의 가중치가 같습니다. \n",
    "\n",
    "둘을 묶어주면 모델의 가중치 개수가 반으로 줄어들고, 과적합 위험도 줄어듭니다.\n",
    "\n",
    "수식으로 표현하자면, 오토인코더가 N개의 레이어를 가진다면 각 레이어들은 다음과 같이 표현 가능합니다.\n",
    "\n",
    "### $W_{N-L+1} = W_L^T$ \n",
    "\n",
    "#### $W_L$은 $L$번째와 $L+1$번째 레이어 사이의 Weight를 의미합니다\n",
    "\n",
    "### $(L = 1,2,3,..., \\frac{N}{2})$\n",
    "\n",
    "fully_connected 함수로는 이를 구현하는게 다소 까다로우니 코드를 수정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "6.284913539886475\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import time\n",
    "\n",
    "n_inputs = n_outputs = 28 * 28\n",
    "n_hidden1 = n_hidden3 = 300\n",
    "n_hidden2 = 150\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.001\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    activation = tf.nn.elu\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    \n",
    "    weights1_init = initializer([n_inputs, n_hidden1])\n",
    "    weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "    weights1 = tf.Variable(weights1_init, dtype=tf.float32)\n",
    "    weights2 = tf.Variable(weights2_init, dtype=tf.float32)\n",
    "    weights3 = tf.transpose(weights2)    \n",
    "    weights4 = tf.transpose(weights1)\n",
    "    # 웨이트 12는 34와 묶였습니다.\n",
    "\n",
    "    biases1 = tf.Variable(tf.zeros(n_hidden1))\n",
    "    biases2 = tf.Variable(tf.zeros(n_hidden2))\n",
    "    biases3 = tf.Variable(tf.zeros(n_hidden3))\n",
    "    biases4 = tf.Variable(tf.zeros(n_outputs))\n",
    "    # 바이어스들은 정규화되지도 않고 묶이지도 않는다는점. 중요합니다!\n",
    "    \n",
    "    hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "    hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)    \n",
    "    hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)    \n",
    "    outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "    \n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "    reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "    # 웨이트 1과 2만 정규화 해주면 됩니다! \n",
    "    loss = reconstruction_loss + reg_loss\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        n_epochs = 1\n",
    "        batch_size = 100\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            n_batches = mnist.train.num_examples // batch_size\n",
    "            for iteration in range(n_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch})\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training One Autoencoder at a Time\n",
    "\n",
    "위 지금까지 데이터 마다 인코더 전체를 학습시켰습니다. 이러지 말고 인코더를 한개씩 학습한다음 쌓아보면 어떨까요.\n",
    "\n",
    "이 방식으로 Deep한 오토인코더를 학습시킨다면 훨씬 빠른 학습이 가능합니다.\n",
    "\n",
    "![](2.png)\n",
    "\n",
    "텐서플로우에서는 단계마다 다른 그래프를 사용하여 구현 가능합니다. \n",
    "\n",
    "그래프를 하나만 쓰는 경우에는 아래 그림처럼 추가적인 작업이 필요합니다.\n",
    "\n",
    "![](3.png)\n",
    "\n",
    "텐서플로우로는 다음처럼 표현 가능합니다.\n",
    "\n",
    "```python\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "with tf.name_scope(\"phase1\"):\n",
    "    phase1_outputs = tf.matmul(hidden1, weights4) + biases4 \n",
    "    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phase1_outputs - X)) \n",
    "    phase1_reg_loss = regularizer(weights1) + regularizer(weights4) \n",
    "    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss \n",
    "    phase1_training_op = optimizer.minimize(phase1_loss)\n",
    "\n",
    "with tf.name_scope(\"phase2\"):\n",
    "    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1)) \n",
    "    phase2_reg_loss = regularizer(weights2) + regularizer(weights3) \n",
    "    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
    "    train_vars = [weights2, biases2, weights3, biases3]\n",
    "    phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Reconstructions\n",
    "\n",
    "오토인코더가 잘 학습되었는지 확인하기 위해, 입력과 출력을 비교해 봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import time\n",
    "\n",
    "n_inputs = n_outputs = 28 * 28\n",
    "n_hidden1 = n_hidden3 = 300\n",
    "n_hidden2 = 150\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.001\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    activation = tf.nn.elu\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    \n",
    "    weights1_init = initializer([n_inputs, n_hidden1])\n",
    "    weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "    weights1 = tf.Variable(weights1_init, dtype=tf.float32)\n",
    "    weights2 = tf.Variable(weights2_init, dtype=tf.float32)\n",
    "    weights3 = tf.transpose(weights2)    \n",
    "    weights4 = tf.transpose(weights1)\n",
    "    # 웨이트 12는 34와 묶였습니다.\n",
    "\n",
    "    biases1 = tf.Variable(tf.zeros(n_hidden1))\n",
    "    biases2 = tf.Variable(tf.zeros(n_hidden2))\n",
    "    biases3 = tf.Variable(tf.zeros(n_hidden3))\n",
    "    biases4 = tf.Variable(tf.zeros(n_outputs))\n",
    "    # 바이어스들은 정규화되지도 않고 묶이지도 않는다는점. 중요합니다!\n",
    "    \n",
    "    hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "    hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)    \n",
    "    hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)    \n",
    "    outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "    \n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "    reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "    # 웨이트 1과 2만 정규화 해주면 됩니다! \n",
    "    loss = reconstruction_loss + reg_loss\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        n_epochs = 1\n",
    "        batch_size = 100\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            n_batches = mnist.train.num_examples // batch_size\n",
    "            for iteration in range(n_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch})\n",
    "        \n",
    "        n_test_digits = 2\n",
    "        X_test = mnist.test.images[:n_test_digits]\n",
    "        outputs_val = outputs.eval(feed_dict={X: X_test})\n",
    "        weights1_val = weights1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA+pJREFUeJzt3c0rfFEcx/Ezv6QspCgl5akkrCgPydLeygILf4bs/Av+\nALGwR1ZSUjbIwsZC8lAWFBtKlPBb/HQ638l8uuM+uPOb92v1PZ0x96ZP5+HOnbmFz89PB5Ty57dP\nAPlGQCAREEgEBBIBgURAIBEQSAQEEgGBVJPx8bhsmx+FKC9iBIFEQCAREEgEBBIBgURAIBEQSAQE\nEgGBREAgERBIBAQSAYFEQCAREEgEBBIBgURAIBEQSAQEEgGBREAgERBIBARS1l+cStzBwYFpLy0t\n+bq1tdX01dXV+Xpubs70NTY2fltXO0YQSAQEUiHjXzlM/GA9PT2mfX5+/qP3aWho8PXo6Gisc/qJ\njo4OXy8sLJi+tra2NA7Jd3MRHwGBREAgVfw2d2Njw7RPTk583d/fb/pOT099fXh4aPo2Nzd9vb29\nbfo6Ozt9fXV1Ffncamrsv7elpcXXNzc3Jf8uXI8459z8/HzkYyaNEQQSAYFU8dvcpLy+vvr6+vra\n9IVTzOXlZeT3rK2tNe1wignf0znn7u/vfb2+vm76JicnIx+zDGxzER8BgURAILEGyVC4tR4bGzN9\nw8PDvt7d3TV94afQCWINgvgICCSmmBQ9Pz+bdnd3t69vb29NX3jj08jISLon9g9TDOIjIJAICKSK\n/zQ3z1ZXV0377u7O101NTaavvb09i1MqGyMIJAICiW1uwi4uLnzd19dn+t7e3nx9dnZm+sItcEbY\n5iI+AgKJgEBim5uwra0tX4drDuecm5qa8nVXV1dm5xQHIwgkAgKJgEDiOkhMxeuMiYkJXx8dHZm+\n8ItbOViDcB0E8REQSGxzY1peXjbt/f19X8/MzJi+HEwrZWMEgURAIBEQSGxzyxT+/ohzzg0NDZl2\nfX29r4+Pj01fztYgbHMRHwGBxDY3gpeXF19PT0+bvvf3d9OenZ31dc6mlB9hBIFEQCAREEhsc7/x\n8fFh2uEntHt7e6avt7fXtMNL7Tl/agTbXMRHQCAxxXzj4eHBtJubm0u+tvhq6eDgYCrnlAKmGMRH\nQCAREEhcav/y+Pjoa/XEqbW1NdMeGBhI7ZzygBEEEgGBxBTzZWVlxdfqiQ7j4+OmXShE2i1WLEYQ\nSAQEEgGBVLVrkOIHMC8uLv7OieQcIwgkAgKpaqeY8MYe55x7enoq+drwpqCUHu6TW4wgkAgIJAIC\nqWrXIErxAwd3dnZ8zRoECBAQSNy0XL24aRnxERBIBARS1tvc//v2q/8QIwgkAgKJgEAiIJAICCQC\nAomAQCIgkAgIJAICiYBAIiCQCAgkAgKJgEAiIJAICCQCAomAQCIgkAgIJAICiYBA+gvJ8MVPMI2A\n7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f454a334400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSP4CQvP5RsK7N2gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f454a267fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABEpJREFUeJzt3c8rNVEcx3G/RUpZEHZ+LeyQhVjIwpIie2EhC0VRlD/C\nRkj5cbPwH1hgRRaSlB0rK8lGkSh5NjrPOVPzae7Mvdfcue/X6ns608w89XnOnDNm5hb//PwUAX5K\n/voEEG8EBBIBgURAIBEQSAQEEgGBREAgERBIZTk+Hrdt46M4yEaMIJAICCQCAomAQCIgkAgIJAIC\niYBAIiCQCAikXN9qj43Dw0On/f7+burr62unb3t723c/a2trTntoaMjUg4ODEc4wHhhBIBEQSMU5\nfi/mT/+aOzc3Z+qtra2sHKOzs9PU5+fnTl9tbW1WjhkSf81FdAQEEgGBlOg5iD3nKCoKPu/o6upy\n2uPj46a+v793+vb39333410eT09PBzp+jjAHQXQEBFLi7qQ+Pj6aemdnx3e73t5ep318fGzq6upq\np6+iosLU39/fTt/Dw4PTvri4MPXLy0uAM443RhBIBAQSAYGUuDmIfd33LuHtecfJyYnTV1NTE2j/\ne3t7Tvvq6sp329HR0UD7jDNGEEgEBFLiLjHd3d2m9i4z7eVqVVVVqP17l85fX1+h9pMvGEEgERBI\nBARS4uYgtkw9wZVKpUx9e3srtx0eHjZ1a2trRo7/lxhBIBEQSIl+YCism5sbp93f32/qz89Pp6+x\nsdFpn52dmbqjoyMLZ5cxPDCE6AgIJAICKdHL3LAuLy+dtnfeYZudnXXaMZ93pI0RBBIBgcQl5tfU\n1JSpj46OfLdbWFhw2svLy1k7pzhgBIFEQCAREEgFe6v97e3Nabe3t5v6+fnZ6WtoaDD13d2d01dX\nV5eFs8sJbrUjOgICqWCXuRMTE07be1mxzc/PmzqPLymhMIJAIiCQCAikglrm2l9QHhgYcPrsF6DG\nxsacPvurzPbLV3mOZS6iIyCQCAikRN8H+fj4cNorKyumVi9d9/T0OO0EzTvSxggCiYBASvQlZnNz\n02mfnp76bms/Uba4uJi1c8o3jCCQCAgkAgIp0bfavd8hU0vb19dXUwf9JGae41Y7oiMgkBK9zE2H\n/RBzSUn4/zeVlZWmLi0tdfrsX4pQ7/t67wCvr68HOrb3eKurq6YuLy8PtA8vRhBIBAQSAYHEHORX\nc3NzRvZjfy+kqanJ6Xt6ejL1xsZGRo6n2P+mmZmZUPtgBIFEQCAl+k6qd1jd3d3N5eHTUlb2/2rv\nXa7aJicnnXZfX5/vtvbnO1taWrzd3ElFdAQEEgGBlOg5iNfBwYGp0/mlKPsXHtJZni4tLTnttrY2\n321HRkZMXV9fH/gYETAHQXQEBFJBXWLg4BKD6AgIJAICiYBAIiCQCAgkAgKJgEAiIJAICCQCAomA\nQCIgkAgIJAICiYBAIiCQcv1ubqCnmBAfjCCQCAgkAgKJgEAiIJAICCQCAomAQCIgkAgIJAICiYBA\nIiCQCAgkAgKJgEAiIJAICCQCAomAQCIgkAgIJAIC6R/mRt8x3HSTRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f454a243278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAACFCAYAAACAJLCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYiRWECOxghiJFcRIrCBGYgUxkn8AyuP2AvnMc+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4548d13ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_image(image, shape=[28,28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "for digit_index in range(n_test_digits):\n",
    "    plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "    plot_image(X_test[digit_index])\n",
    "    plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "    plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Features\n",
    "\n",
    "비교사 학습인 오토인코더를 응용해서 데이터의 특징을 찾아낼 수 있습니다.\n",
    "\n",
    "사진에서 고양이를 탐지하는 기술로 예를 들어보겠습니다. 고양이가 없는 사진을 학습하다가 고양이가 있는 사진이 나타나면,\n",
    "\n",
    "오토인코더 안의 뉴런들이 이전에 없던 데이타의 특징으로 인해 고양이 사진에 대해 활발한 뉴런활동을 보여줄 것입니다.\n",
    "\n",
    "이는 가장 위의 (디코더와 가장 가까운) 히든 레이어에서 가장 부각됩니다. \n",
    "\n",
    "가장자리 레이어일수록 데이터에서 상대적으로 알아보기 쉽고 큰 특징을 잡아내기 때문입니다.\n",
    "\n",
    "방금전의 mnist를 학습한 오토인코더의 첫벗째 히든 레이어를 살펴보겠습니다.\n",
    "\n",
    "이 레이어에서 처음 다섯개의 뉴런은 데이타로부터 어떤 특징을 잡아냈는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4549d8ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f454b037eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB8NJREFUeJztnUeLF1sQxX8z5pwTmFHBCAYUFFR0q251IaILFwqCA34B\nl4L4BRQRwZ0LA7pSEUVU1IU5oIIJc85x3uJx5nbXdI/tW3Q5vDqbPx1u3zvFuVXnVt3uaWhubibg\ng0bvAfyfEcZ3RBjfEWF8R4TxHRHGd0QY3xFhfEeE8R3Rsc7Otm3b1gzQseO/3f78+bPwPl0vWn2r\nTYcOHXLHDQ0NuTb22Pb569ev3Hn7/Ox5O071/f37dwAaGxtzfTU1NTUU/mEGwXxH1Mp8sUms1K8g\nRv348SN3v46zEBs7deoEJBbqmWLj72aXnq3n6Lyelz2nZ6mN+tC4/xTBfEfUynxBvlG/Yo718UWs\ntYwty8qKlZoJRb48e1+W6RZ25qmN9fVls6wMwXxH1Mp8McUqDatgBKtcsrAMtm3VR5kasrDnNda2\n2mpG6Lod0+8QzHdErcz/9u0bkJSF9aXWL+s4yzgbJ8Rw/YqxnTt3BqB3794AfPz4MdeXrj9//jzX\nXizWcbZPjcvGKP09f1oVDOY7olbmW01uzwuWUVlYxls/O2LECABu3rwJwLhx4wAYO3Zs7pk7duzI\nHffs2TP33Cx0TjNXqKq8yhDMd4SLzpe/tUyRvxWTxPKiFaR8e7du3XJtdH7lypUA3Lp1C0jMf/Lk\nCQB9+vQBYNmyZQBcunQJgPHjxwNw7ty5lr6ePXuW60OxqHv37oV/R1UE8x1RK/PLfKNdZYrpX758\nAfJ+WPdKxdy+fRtIvl6qZuvWrQCsXr0agP379wNw8OBBAI4cOQLA/PnzAVi4cCEADx48AODly5ct\nfcq3azwan2JAly5dcmOrimC+I8L4jnAJuAqsNoWsQKbpbFO40HoxJTdx4sQJAAYOHAjA69evAVix\nYgUA06ZNA5IE3bhxIwAHDhwAYP369UAKonJjANeuXcuNR+O2i6tIrLUj1Mr8oqV7EcqSYpCkopi/\nfPlyAHbu3AnAq1evADh9+jQA69atA5JcnDlzJpAC6rBhw4AkLb9+/QrAvXv3WvrUOUlkMd4m1NpK\nSxchmO+IWpnfVooYWifFdJ8WUgDv3r0Dkk8+dOgQAKtWrQKSD9f1OXPmACkWSKIeO3YMSGmFo0eP\nAjBv3jwgsT07Hv3K59tCf0jNdgSXArogxtgkmRgk5dGjR4+WNqNGjQJSPJgwYQKQfL5igBj++fNn\nAPr27QvAlStXcn1I/UyaNAlIyiarsHSv3QBgZ/KfFtKD+Y5wLaCLXfKldgZo2d6/f/+WtromRiud\nMH36dACuX78OpJmxePFiAO7evQukBNvIkSOBpJ4ePnyYG1PXrl1bjdcW5a1qC5/fjvBXqB27arWq\nR/4akv8/efIkAI8ePQKSvpdKmTt3LgBnz54F0gxoamoCkr5fs2YNAPfv3wegX79+QF6zW/1ux1m0\nHqmCYL4jamW+9ZG2rGh9pq5nNff79++BpPfHjBkDwL59+4DEcPnyWbNmAYnxp06dAmDLli0A7Nmz\nB4AZM2bkxpJlsVRM1Y1YVRHMd0StzLdZTLtJ1caEos1UWrleuHABSPpcPl6xQEWUzZs3A2nle/z4\ncQD27t0LwKJFiwCYPHkyAFevXs2NAdJssEUgjatqzsoimO8IF51vUbbdW2W7bEnvw4cPAEycODHX\nZunSpQBs2rQJgDNnzgBw+fJlALZv3w4kBaXYsHv3bgA2bNiQG0s2ztiVt2as1iE2C1sVwXxH1Mp8\nqySsLrYVLDFfCgdg9OjRQMq3Dx8+HICnT58CaU0wdepUAN6+fQvA7Nmzc8/S+mDBggVAWtG+ePEC\nSDMEWqscm9uxWw2rIpjvCNct4oJYJsZ/+vQJgDdv3gDJz0OqSKkmqzZSN9L/yv2olqtNUmqvmTJl\nyhQgzTplSVUbhtZbQ6wqszOjKoL5jvgrXo6wTJKv1wy4ceNGyzOkbvQMzQBVotTW6v4hQ4YAcP78\neSDFgsePHwNpZqhqpuPsuCxsDIuNsu0ItTLf6nmrHjQzdF36XmyG5JP1K50upmpL+J07d4BUuTp8\n+DAAS5YsAVI+XzGhV69eQIoZqoRBaxVmVU6onXYIl307dgu4zQpKXQwdOhTI59NV1dq1axcAgwYN\nAmDw4MFAigHatyNGDxgwAEg1W+1mUGVLisqOMQv76QDNUPspgqoI5jsijO8I15SyAqx9S1FyT25H\nbgiSNNRGVxW+L168CKQiiYosShWvXbsWSG+gZNMH0LZctIG0zDXFe7jtCC4FdPu9mjKJpmJ5tpii\nZ2griAKqEm7aNqjFlKC+JEWVXpC0tMm8LOz4yjbGFgXpthDMd4Sr1LQ+0hYldD27UVbSUFsJ5bvF\n/GxCDJLEVEwQ9Gz1WfY2fFEb+z7uf/3uTjDfEa5lRPlM+y0Gu50w+ya6zsk3a3EkxisZJ3bKp9tt\n3vbLUoJmQlvfd7PlTjuLqiKY7wjXF+IsLAuLtmxY36x7bJLLfiHEFsF1n2aQ1f1Fmt3GgbItL1UR\nzHeEyxvoZStB++Wmou/YWEVRxvAy5WG/71a26bUIZd+Cs5u8qiKY74iG+J8pfgjmOyKM74gwviPC\n+I4I4zsijO+IML4jwviOCOM7IozviDC+I8L4jgjjOyKM74gwviPC+I4I4zsijO+IML4jwviOCOM7\nIozviDC+I/4BZVL04Bix4pgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f454b840dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB2ZJREFUeJztnceOFUkThb/Ge+9BgACBMAIEK5awZcOrsuIJkIANEsIL\n4RHeez+L//8ms6Kb4TKLG2pNnE1RVVmZSeiEycjI2xM/f/6kkIMZ2RP4L6OEn4gSfiJK+Iko4Sei\nhJ+IEn4iSviJKOEnYtY4Bzt58uRPgC9fvgAwc+ZMAGbMGHLg06dPAExMTEx6P3v2bAC+fv066MOV\n+qxZ//svffv2bfD+48ePAMyZM2fQzrFsF5/33wjnP2/ePAC+f/8+6OPEiRMT/yiI/6OYn4ixMl/G\n/PjxA2iM9j4ySvbJ9h4+k9Hz588HmgbIfLUnXn81lt/ZHzQtc75qgoy3rz9FMT8RY2V+hDby8+fP\ng3vZGW0tNBbK/OgXopbI5KgpkcULFy4Emhb22V7b+Mw5eG9fc+fOHen/LYr5iRgr82OEop2NEYq2\nVEZ5D42Z0R9EWx9Z6Nja+KgxPvd72081bxE1U60aFcX8RIyV+drVGHPLPtn7/v17YOoo58OHD8Dk\nOH7BggUALF68GGh+xKt9LV26FIDly5cP2huxvHnzZjDHvg/nFf2Iz6Nm/A7F/ESMlfkxJo/Pe9sO\n8Pz5c6CxHeDt27eDtmqPDH7w4AEAz549A5qP2LJlCwAbN24EYPv27YPvZXdcB0w1lj7Aeetf/HZU\nFPMTMVbmy4yeydBsvQyTra9evQLg6dOnf7d9+fIl0Fi4Zs0aoDH17t27ANy7d2/w7fHjxwFYtmwZ\n0OyzWqjfWbFiBQDv3r37e0zn67yMzuL9n6KYn4ixMt/oIGYitZ2+f/jwIdBYru2HFmls3boVgEOH\nDgHw+vVrAO7cuTP4VqavXr0aaCyW2WqMV21/H8NHv+AcjLAqtzMNUcJPxFjNTkwXqK4xvNORee1T\nBRs2bADg2LFjQAshL1y4ADQTtmnTJqCZG02doapm6cWLF0AzT4asmpb+3zF9oAlzfnFT6Hco5idi\nrMyXybLQa1xc6eAMA/tQ7siRIwDs2bMHaOwzxHQBZCpj586dQHOOasiVK1eA5kQPHz4MwI4dOyaN\n6fxiSGyf9uH9qCjmJyLF5seydFkWQzZtqXYbWnpAyPjbt28DjYXbtm0DYNWqVUBbsJ07dw6As2fP\nArBu3ToADh48CDSb39tvE2dRQ+P2Yu8nRkExPxEpiTWjGxmvjfd93CqUjf0zmXz+/HmgLcxMFcto\n/UxMO9j+wIEDwOToaKqFnfNVc2Mi7U8XW8X8RKTY/Lh5rU2NmGoj3TSCcbqJMxlrvK723Lp1C4Cr\nV68CjfmmlI8ePQrA/v37B2NNtY0YNVJNcJ7RJ/wOxfxEpJSOxBXsr6IdoX2Hxi7je9/F7UUTbF4f\nP348GHPfvn1AWzHHssK+XNA+Y2JNxrse8f2oKOYnYqzMj4WxsisWJXmVSb39NRejljx58gRocb4a\n4Ea5K1m/27x5M9Dstu2NfhxT39K3cR4y3nIT31duZxphrMzXVsqYGN/HlaLs7vMsao+2OxZB2Vbf\noE0XbrAbBV28eHEwllrX23zfxVyTWhLLBkdFMT8RqdFOLNXTzvpcNvfFSOvXrwdg0aJFAOzevRuA\nvXv3Dr41L6QvOHPmDNDy+WqEDDca0n73Yzo/n8VDEfqPqYq8/gnF/ESMlfnxAEM8TmOEIvt876oV\nWrbS7KZ5e/1H3LE6deoUAI8ePQLaStgVrmPevHkTmDpWjzmdeI2HPEZFMT8RKdGOTIor21iWp123\nMApg5cqVAKxdu3bQJo4h07Xl5vXN5egjfG8UZElJv+cQ4/uY05Hxlc+fRkhlfiwVl0nm741Y+sLa\n+EyGyj5ZeuPGDaCtbHft2jW4qgky3jn5fT9mPDIUs7LxflQU8xORUi4Yd7RklPey2WqAnlGyzIjI\nNn5rjubatWtAY61VCfoMoxr7cV8g5pv6Z/YVy8nVxsrnTyOMlfkyOh4+i/G+TPLarzZjDkbIXOty\nrl+/PujDKMZjP/fv3wdaNYMaY/TU1+C4zliyZAkwebcrHuwbFcX8RJTwE5F6DjfWucdTfl77Qlkd\nrn0ZSmp2Tp8+DbRNFsNWF1OXLl0C4PLly0DbZhSaFNMO/TziCflfnS0bFcX8RKRsI8aFTFwgyb6Y\nduj/bbmJDtSiKJ2iCTTHkJUyPSbzhKlmz2b1baPWRQcbNeF3KOYnYqzMl7WGmrIxpmbjYqVPWMl0\nU8ZeDR1dAEUN8N6x428z/Kp8HSb/ulUsBf+3v7tTzE9E6jaiNtIlftyGUxP6Mg4ZK8u0/WqPDJe5\nRjvacO10XMDFFEefXnBeseQlHo6oDfRphBTmx224eCDOe5k1VbSjv4jlKH2U0vcVvxdGO5G9/Zag\n84q/7RMLfP/0bxEU8xMxVubLzlgGKGP0ATGW7yMPGR+LbL2aGIu/GOV9PGwXfzctrgumahPj+7j9\nOSqK+YmYqL+ZkodifiJK+Iko4SeihJ+IEn4iSviJKOEnooSfiBJ+Ikr4iSjhJ6KEn4gSfiJK+Iko\n4SeihJ+IEn4iSviJKOEnooSfiBJ+Ikr4iSjhJ+IvkBNu3tYIHTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4551df67b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8eAb8h9hxfhjmzqQGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45497ff6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5): \n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plot_image(weights1_val.T[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "또는 오토인코더에 임의의 입력 이미지를 제공하고 관심있는 뉴런의 활성화를 관찰 후 \n",
    "\n",
    "역전파를 수행하여 뉴런이 더 많이 활성화되는 방식으로 이미지를 조정하는 것입니다. \n",
    "\n",
    "이 과정을 반복하면 이미지가 점차적으로 가장 뉴런에게 흥미로운 이미지로 바뀝니다. \n",
    "\n",
    "이것은 뉴런이 찾고있는 특징의 입력을 시각화하는 유용한 기술입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Pretraining Using Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 알고리즘에서 과제 수행을 위한 데이터가 부족하다면 비슷한 과제를 수행하는 신경망 알고리즘을 찾고\n",
    "\n",
    "그 신경망의 하위 계층을 재사용하는 방법이 있습니다. 예를 들어 아시아인 얼굴을 구분하는 신경망을 만들고자 할 때,\n",
    "\n",
    "일단 이미 존재하는 사람의 얼굴을 학습한 분류기를 사용해 적은데이타로 '얼굴'에 대한 학습이 완료된 상태에서\n",
    "\n",
    "아시아인을 학습할 수 있습니다.\n",
    "\n",
    "같은 아이디어로, 오토인코더를 이용해서도 응용 가능합니다.\n",
    "\n",
    "![](4.png)\n",
    "\n",
    "###### 볼츠만 머신 이야기가 나옴.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "\n",
    "데이타에 노이즈를 추가하고 최종 출력은 잡음 없는 데이타가 되도록 교육하는 방법도 있습니다.\n",
    "\n",
    "이렇게하면 자동 코더가 입력을 출력에 쉽게 복사하지 못하고 데이터에서 패턴을 찾아내야합니다.\n",
    "\n",
    "![](5.png)\n",
    "\n",
    "텐서플로우로 구현하는 것은 간단합니다. (드롭아웃 예제)\n",
    "\n",
    "```python\n",
    "keep_prob = 0.7\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "is_training = tf.placeholder_with_default(False, shape=(), name='is_training')\n",
    "X_drop = dropout(X, keep_prob, is_training=is_training)\n",
    "\n",
    "[...]\n",
    "hidden1 = activation(tf.matmul(X_noisy, weights1) + biases1)\n",
    "[...]\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE \n",
    "[...]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(training_op, feed_dict={X: X_batch, is_training: True})\n",
    "    # 테스트 과정에서는 False\n",
    "    [...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoders\n",
    "\n",
    "Sparsity를 이용해 더 효과적으로 특징을 추출 할 수 있습니다.\n",
    "\n",
    "비용 함수에 적절한 항을 추가함으로써, 오토인코더가 코딩 레이어 뉴런의 활성화 정도를 줄이도록 유도합니다.\n",
    "\n",
    "결과적으로 작은 특징들의 조합으로 데이타를 표현하는 인코더가 만들어 지게 됩니다.\n",
    "\n",
    "일반적으로 이로인해 코딩 레이어의 각 뉴런들이 유용한 특징들을 잘 찾아내게 됩니다.\n",
    "\n",
    "###### \"비용 함수에 적절한 항을 추가함으로써, 오토인코더가 코딩 레이어의 활성 뉴런 수를 줄이도록 유도합니다. \"\n",
    "\n",
    "위 문장을 실현하기 위해서 반복되는 트레이닝 과정에서 코딩 레이어의 각 뉴런이 얼마나 활성화 되는지 측정해야합니다. \n",
    "\n",
    "뉴런당 평균적으로 얼마나 활성화 되는지를 비용함수에 추가해 주고 활동량이 큰 뉴런에 패널티를 줍니다.\n",
    "\n",
    "예를 들어 뉴런의 평균 활성화 횟수가 0.3이지만 타겟 Sparsity가 0.1이라면 페널티를 적용하게 됩니다.\n",
    "\n",
    "![](6.png)\n",
    "\n",
    "###### 으으..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders\n",
    "\n",
    "Variational 오토인코더는 가장 인기있는 오토인코더 종류중 하나이며, 지금까지 논의한 모든 오토인코딩과는 상당히 다릅니다.\n",
    "\n",
    "확률론적 오토인코더이며, 트레이닝 이후에도 출력이 확률적으로 결정됩니다.\n",
    "\n",
    "또한 Generative 오토인코더입니다. 트레이닝데이타에서 샘플링 한 것처럼 보이는 새로운 인스턴스를 생성 할 수 있습니다.\n",
    "\n",
    "![](7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 으으 ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

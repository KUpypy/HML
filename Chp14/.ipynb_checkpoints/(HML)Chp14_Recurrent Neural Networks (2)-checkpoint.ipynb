{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RNNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RNN을 훈련 시키는 과정은 간단합니다.\n",
    "시간축에 따라 네트워크를 펼친 후 역전파를 사용하면됩니다.\n",
    "이 전략은 BPTT (backpropagation through time)라고합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8.png\" width=400 align=right>\n",
    "\n",
    "보통의 역전파처럼 \n",
    "\n",
    "점선의 화살표로 표시된 \n",
    "\n",
    "출력들이 있습니다 ($Y$).\n",
    "\n",
    "무시 된 출력을 제외하고\n",
    "\n",
    "cost function 을 계산합니다\n",
    "\n",
    "C($t_{min}, t_{min+1}, ..., t_{max}$)\n",
    "\n",
    "해당 비용 함수의 그라디언트는 실선의 네트워크를 통해 역 전파됩니다. \n",
    "\n",
    "그라디언트는 최종 출력뿐만 아니라 비용 함수가 사용하는 모든 출력을 거쳐 흐릅니다.\n",
    "\n",
    "($Y_{(2)}, Y_{(3)}, Y_{(4)}$를 통해 $Y_{(0)}, Y_{(1)}$로 흐릅니다.)\n",
    "\n",
    "W 및 b는 각각의 시간 단계에서 동일하기 때문에, 이 과정에 문제는 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Sequence Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"9.png\" width=300 align=right>\n",
    "\n",
    "RNN으로 MNIST 이미지를 분류해 봅시다. \n",
    "\n",
    "CNN이 이미지 분류에 더 적합하지만, \n",
    "\n",
    "이 과정이 RNN을 이해하기 편합니다.\n",
    "\n",
    "시간축에 따라 펼쳐진 RNN이 \n",
    "\n",
    "숨겨진 레이어를 대체한다는 특징만 빼고,\n",
    "\n",
    "단순한 MNIST 분류기와 거의 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "완전히 연결된 레이어는 RNN의 최종 상태(즉, 28 번째 출력) 만 포함하는 상태 텐서에 연결됩니다. 또한 y는 대상 클래스의 자리 표시 자입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0 Train accuracy: 0.85 Test accuracy: 0.9226\n",
      "1 Train accuracy: 0.95 Test accuracy: 0.9586\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps, n_inputs = 28, 28\n",
    "# 우리는 각각의 이미지를 각각 [1 by 28픽셀] 의 28행 시퀀스로 취급 합니다.\n",
    "# (각 MNIST 이미지는 28 × 28 픽셀이기 때문에)\n",
    "\n",
    "n_neurons = 150\n",
    "# 150개의 RNN 뉴런으로 레이어를 구성합니다\n",
    "\n",
    "n_outputs = 10\n",
    "# 출력에 연결된 10 개의 뉴런(클래스 당 하나)을 포함하는 softmax 레이어를 사용합니다\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels\n",
    "# mnist 데이타를 가져옵니다.\n",
    "\n",
    "n_epochs, batch_size = 2, 20\n",
    "# 배치사이즈와 에폭을 정합니다.\n",
    "# 시간이 너무 오래걸려서 사이즈를 줄였습니다. 원래는 100, 150입니다.\n",
    "\n",
    "learning_rate = 0.001\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "logits = fully_connected(states, n_outputs, activation_fn=None)\n",
    "# 네트워크 그래프를 그립니다.\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# cost function을 정의합니다.\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 세션 시작\n",
    "with tf.Session() as sess: \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training to Predict Time Series\n",
    "\n",
    "<img src=\"10.png\" width=600>\n",
    "\n",
    "```\n",
    "주식 가격, 기온, 뇌파 등과 같은 시계열을 다루는 방법을 살펴 봅시다. \n",
    "생성 된 시계열에서 다음 값을 예측하기 위해 RNN을 학습해봅니다. \n",
    "\n",
    "타겟 시퀀스는 입력 시퀀스와 동일한 성질을 가지지만,\n",
    "끝에서 한 단계 미래를 예측하고자 합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps, n_inputs, n_neurons, n_outputs = 20, 1, 100, 1\n",
    "# 20개의 연속 스텝\n",
    "# 인풋은 점 하나\n",
    "# 100개의 RNN뉴런\n",
    "# 아웃풋도 점 하나\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"11.png\" width=400 align=\"right\">\n",
    "\n",
    "이 경우 각 시간 단계마다 \n",
    "\n",
    "크기 100의 출력 벡터가 생깁니다.\n",
    "\n",
    "그러나 실제로 원하는 것은 \n",
    "\n",
    "각 시간 단계에서 단일 출력 값입니다. \n",
    "\n",
    "OutputProjectionWrapper을 이용해\n",
    "\n",
    "이 문제를 해결합니다.\n",
    "\n",
    "이 셀래퍼는 기본 셀과 같은 역할을하며 거기에 더해 일부 기능을 추가합니다.\n",
    "\n",
    "OutputProjectionWrapper는 각 출력 상단에 선형 뉴런(즉, activation function없이 바로 연결된) \n",
    "\n",
    "fully-connected 레이어를 추가합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps, n_inputs, n_neurons, n_outputs = 20, 1, 100, 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_iterations, batch_size = 2, 20\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "    output_size=n_outputs)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "# 코스트펑션을 그려줍니다.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = [...]\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) \n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"12.png\" width=500>\n",
    "\n",
    "---\n",
    "```python\n",
    "X_new = [...] # New sequences\n",
    "y_pred = sess.run(outputs, feed_dict={X: X_new})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```\n",
    "시계열 데이타의 부족 및 배치생성에 대한 개념 부족으로 코드를 돌릴 수 없습니다.\n",
    "교재에서 말하는 바로는 위의 그림처럼 예측이 된다고 합니다.\n",
    "```\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"13.png\" width=600>\n",
    "\n",
    "```\n",
    "OutputProjectionWrapper를 사용하는 것이 \n",
    "RNN의 출력 시퀀스의 차원을 하나의 값으로 줄이는 가장 간단한 솔루션이지만 \n",
    "이보다 더 (까다 롭지만) 효율적인 해결책이 있습니다. \n",
    "\n",
    "[batch_size, n_steps, n_neurons]에서 \n",
    "[batch_size * n_steps, n_neurons]까지의 RNN 출력을 \n",
    "재구성 한 다음 적절한 출력 크기를 가진 단일 연결 레이어를 적용 할 수 있습니다(이 경우에는 1).\n",
    "\n",
    "이것은 결과 텐서 형태의 [batch_size * n_steps, n_outputs]가 될 것이고\n",
    "이 텐서를 [batch_size, n_steps, n_outputs]로 바꿀 것입니다.\n",
    "```\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps, n_inputs, n_neurons, n_outputs = 20, 1, 100, 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_iterations, batch_size = 2, 20\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,\n",
    "    activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = fully_connected(\n",
    "    stacked_rnn_outputs, n_outputs,\n",
    "    activation_fn=None)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "# 이로인해 이전보다 속도향상을 기대할 수 있습니다.\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = [...]\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) \n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative RNN\n",
    "## Deep RNNs\n",
    "## Distributing a Deep RNN Across Multiple GPUs\n",
    "## Applying Dropout\n",
    "## The Difficulty of Training over Many Time Steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
